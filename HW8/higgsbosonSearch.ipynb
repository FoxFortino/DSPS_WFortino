{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "higgsbosonSearch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FoxFortino/DSPS_WFortino/blob/main/HW8/higgsbosonSearch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xpw06PzTsU6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55d5e2ba-1d43-4a71-c0df-95f6048850d7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nS4S7msAPK_R"
      },
      "source": [
        "- Download the Higgs boson data from Kaggle (programmatically within the notebook)\n",
        "see how I did it in the Titanic Trees notebook https://github.com/fedhere/DSPS/blob/master/lab9/titanictree.ipynb\n",
        "\n",
        "find the correct API link here https://www.kaggle.com/c/higgs-boson/data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hl1Dz7VeNgzk"
      },
      "source": [
        "import json\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from sklearn.model_selection import train_test_split as tts\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.model_selection import RandomizedSearchCV"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ee4bN6aENaHO"
      },
      "source": [
        "envs = json.load(open(\"/content/drive/MyDrive/.kaggle/kaggle.json\", \"r\"))\n",
        "os.environ[\"KAGGLE_USERNAME\"] = envs['username']\n",
        "os.environ[\"KAGGLE_KEY\"] = envs['key']"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hSmeTUCPM8df"
      },
      "source": [
        "# !mkdir -p /content/drive/MyDrive/Higgs"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1LWCZ9_NpY8"
      },
      "source": [
        "# !cd /content/drive/MyDrive/Higgs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jR-0cyC3NTop"
      },
      "source": [
        "# !kaggle competitions download -c higgs-boson"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zbfc0A0GPH-h",
        "outputId": "1218c4f3-58d3-47c5-cec5-f6f8a79c2c9e"
      },
      "source": [
        "!ls /content/drive/MyDrive/Higgs"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "HiggsBosonCompetition_AMSMetric_rev1.py  test.zip\n",
            "random_submission.zip\t\t\t training.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMuvMJgOnlYo"
      },
      "source": [
        "\n",
        "- Read in the trainind data. Split the provided training data into a training and a test set. \n",
        "The last 2 columns are what you want to predict: \"weight\" and \"label\".\n",
        "Remove them from the input data and create a separate variable label and a separate variable weight, which will be your target variables for, respectively, classification and regression.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zHCi2xINNPW-",
        "outputId": "e55caec2-24b9-472e-d246-da121a53e32c"
      },
      "source": [
        "higgsdata = pd.read_csv(\"/content/drive/MyDrive/Higgs/training.zip\")\n",
        "\n",
        "label = higgsdata[\"Label\"]\n",
        "weight = higgsdata[\"Weight\"]\n",
        "higgsdata = higgsdata.drop(columns=[\"Label\", \"Weight\"])\n",
        "higgsdata.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(250000, 31)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "muWGBHN90IPN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "outputId": "2abb751b-4074-4ebc-8ec6-434176f0f988"
      },
      "source": [
        "higgsdata.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EventId</th>\n",
              "      <th>DER_mass_MMC</th>\n",
              "      <th>DER_mass_transverse_met_lep</th>\n",
              "      <th>DER_mass_vis</th>\n",
              "      <th>DER_pt_h</th>\n",
              "      <th>DER_deltaeta_jet_jet</th>\n",
              "      <th>DER_mass_jet_jet</th>\n",
              "      <th>DER_prodeta_jet_jet</th>\n",
              "      <th>DER_deltar_tau_lep</th>\n",
              "      <th>DER_pt_tot</th>\n",
              "      <th>DER_sum_pt</th>\n",
              "      <th>DER_pt_ratio_lep_tau</th>\n",
              "      <th>DER_met_phi_centrality</th>\n",
              "      <th>DER_lep_eta_centrality</th>\n",
              "      <th>PRI_tau_pt</th>\n",
              "      <th>PRI_tau_eta</th>\n",
              "      <th>PRI_tau_phi</th>\n",
              "      <th>PRI_lep_pt</th>\n",
              "      <th>PRI_lep_eta</th>\n",
              "      <th>PRI_lep_phi</th>\n",
              "      <th>PRI_met</th>\n",
              "      <th>PRI_met_phi</th>\n",
              "      <th>PRI_met_sumet</th>\n",
              "      <th>PRI_jet_num</th>\n",
              "      <th>PRI_jet_leading_pt</th>\n",
              "      <th>PRI_jet_leading_eta</th>\n",
              "      <th>PRI_jet_leading_phi</th>\n",
              "      <th>PRI_jet_subleading_pt</th>\n",
              "      <th>PRI_jet_subleading_eta</th>\n",
              "      <th>PRI_jet_subleading_phi</th>\n",
              "      <th>PRI_jet_all_pt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100000</td>\n",
              "      <td>138.470</td>\n",
              "      <td>51.655</td>\n",
              "      <td>97.827</td>\n",
              "      <td>27.980</td>\n",
              "      <td>0.91</td>\n",
              "      <td>124.711</td>\n",
              "      <td>2.666</td>\n",
              "      <td>3.064</td>\n",
              "      <td>41.928</td>\n",
              "      <td>197.760</td>\n",
              "      <td>1.582</td>\n",
              "      <td>1.396</td>\n",
              "      <td>0.2</td>\n",
              "      <td>32.638</td>\n",
              "      <td>1.017</td>\n",
              "      <td>0.381</td>\n",
              "      <td>51.626</td>\n",
              "      <td>2.273</td>\n",
              "      <td>-2.414</td>\n",
              "      <td>16.824</td>\n",
              "      <td>-0.277</td>\n",
              "      <td>258.733</td>\n",
              "      <td>2</td>\n",
              "      <td>67.435</td>\n",
              "      <td>2.150</td>\n",
              "      <td>0.444</td>\n",
              "      <td>46.062</td>\n",
              "      <td>1.24</td>\n",
              "      <td>-2.475</td>\n",
              "      <td>113.497</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100001</td>\n",
              "      <td>160.937</td>\n",
              "      <td>68.768</td>\n",
              "      <td>103.235</td>\n",
              "      <td>48.146</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.473</td>\n",
              "      <td>2.078</td>\n",
              "      <td>125.157</td>\n",
              "      <td>0.879</td>\n",
              "      <td>1.414</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>42.014</td>\n",
              "      <td>2.039</td>\n",
              "      <td>-3.011</td>\n",
              "      <td>36.918</td>\n",
              "      <td>0.501</td>\n",
              "      <td>0.103</td>\n",
              "      <td>44.704</td>\n",
              "      <td>-1.916</td>\n",
              "      <td>164.546</td>\n",
              "      <td>1</td>\n",
              "      <td>46.226</td>\n",
              "      <td>0.725</td>\n",
              "      <td>1.158</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>46.226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100002</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>162.172</td>\n",
              "      <td>125.953</td>\n",
              "      <td>35.635</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.148</td>\n",
              "      <td>9.336</td>\n",
              "      <td>197.814</td>\n",
              "      <td>3.776</td>\n",
              "      <td>1.414</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>32.154</td>\n",
              "      <td>-0.705</td>\n",
              "      <td>-2.093</td>\n",
              "      <td>121.409</td>\n",
              "      <td>-0.953</td>\n",
              "      <td>1.052</td>\n",
              "      <td>54.283</td>\n",
              "      <td>-2.186</td>\n",
              "      <td>260.414</td>\n",
              "      <td>1</td>\n",
              "      <td>44.251</td>\n",
              "      <td>2.053</td>\n",
              "      <td>-2.028</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>44.251</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100003</td>\n",
              "      <td>143.905</td>\n",
              "      <td>81.417</td>\n",
              "      <td>80.943</td>\n",
              "      <td>0.414</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.310</td>\n",
              "      <td>0.414</td>\n",
              "      <td>75.968</td>\n",
              "      <td>2.354</td>\n",
              "      <td>-1.285</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>22.647</td>\n",
              "      <td>-1.655</td>\n",
              "      <td>0.010</td>\n",
              "      <td>53.321</td>\n",
              "      <td>-0.522</td>\n",
              "      <td>-3.100</td>\n",
              "      <td>31.082</td>\n",
              "      <td>0.060</td>\n",
              "      <td>86.062</td>\n",
              "      <td>0</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100004</td>\n",
              "      <td>175.864</td>\n",
              "      <td>16.915</td>\n",
              "      <td>134.805</td>\n",
              "      <td>16.405</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>3.891</td>\n",
              "      <td>16.405</td>\n",
              "      <td>57.983</td>\n",
              "      <td>1.056</td>\n",
              "      <td>-1.385</td>\n",
              "      <td>-999.0</td>\n",
              "      <td>28.209</td>\n",
              "      <td>-2.197</td>\n",
              "      <td>-2.231</td>\n",
              "      <td>29.774</td>\n",
              "      <td>0.798</td>\n",
              "      <td>1.569</td>\n",
              "      <td>2.723</td>\n",
              "      <td>-0.871</td>\n",
              "      <td>53.131</td>\n",
              "      <td>0</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>-999.00</td>\n",
              "      <td>-999.000</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   EventId  DER_mass_MMC  ...  PRI_jet_subleading_phi  PRI_jet_all_pt\n",
              "0   100000       138.470  ...                  -2.475         113.497\n",
              "1   100001       160.937  ...                -999.000          46.226\n",
              "2   100002      -999.000  ...                -999.000          44.251\n",
              "3   100003       143.905  ...                -999.000          -0.000\n",
              "4   100004       175.864  ...                -999.000           0.000\n",
              "\n",
              "[5 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCPS73k0ytqj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 317
        },
        "outputId": "c6f0e1a0-27c6-492f-f47d-b9496b05b18f"
      },
      "source": [
        "higgsdata.describe()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EventId</th>\n",
              "      <th>DER_mass_MMC</th>\n",
              "      <th>DER_mass_transverse_met_lep</th>\n",
              "      <th>DER_mass_vis</th>\n",
              "      <th>DER_pt_h</th>\n",
              "      <th>DER_deltaeta_jet_jet</th>\n",
              "      <th>DER_mass_jet_jet</th>\n",
              "      <th>DER_prodeta_jet_jet</th>\n",
              "      <th>DER_deltar_tau_lep</th>\n",
              "      <th>DER_pt_tot</th>\n",
              "      <th>DER_sum_pt</th>\n",
              "      <th>DER_pt_ratio_lep_tau</th>\n",
              "      <th>DER_met_phi_centrality</th>\n",
              "      <th>DER_lep_eta_centrality</th>\n",
              "      <th>PRI_tau_pt</th>\n",
              "      <th>PRI_tau_eta</th>\n",
              "      <th>PRI_tau_phi</th>\n",
              "      <th>PRI_lep_pt</th>\n",
              "      <th>PRI_lep_eta</th>\n",
              "      <th>PRI_lep_phi</th>\n",
              "      <th>PRI_met</th>\n",
              "      <th>PRI_met_phi</th>\n",
              "      <th>PRI_met_sumet</th>\n",
              "      <th>PRI_jet_num</th>\n",
              "      <th>PRI_jet_leading_pt</th>\n",
              "      <th>PRI_jet_leading_eta</th>\n",
              "      <th>PRI_jet_leading_phi</th>\n",
              "      <th>PRI_jet_subleading_pt</th>\n",
              "      <th>PRI_jet_subleading_eta</th>\n",
              "      <th>PRI_jet_subleading_phi</th>\n",
              "      <th>PRI_jet_all_pt</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "      <td>250000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>224999.500000</td>\n",
              "      <td>-49.023079</td>\n",
              "      <td>49.239819</td>\n",
              "      <td>81.181982</td>\n",
              "      <td>57.895962</td>\n",
              "      <td>-708.420675</td>\n",
              "      <td>-601.237051</td>\n",
              "      <td>-709.356603</td>\n",
              "      <td>2.373100</td>\n",
              "      <td>18.917332</td>\n",
              "      <td>158.432217</td>\n",
              "      <td>1.437609</td>\n",
              "      <td>-0.128305</td>\n",
              "      <td>-708.985189</td>\n",
              "      <td>38.707419</td>\n",
              "      <td>-0.010973</td>\n",
              "      <td>-0.008171</td>\n",
              "      <td>46.660207</td>\n",
              "      <td>-0.019507</td>\n",
              "      <td>0.043543</td>\n",
              "      <td>41.717235</td>\n",
              "      <td>-0.010119</td>\n",
              "      <td>209.797178</td>\n",
              "      <td>0.979176</td>\n",
              "      <td>-348.329567</td>\n",
              "      <td>-399.254314</td>\n",
              "      <td>-399.259788</td>\n",
              "      <td>-692.381204</td>\n",
              "      <td>-709.121609</td>\n",
              "      <td>-709.118631</td>\n",
              "      <td>73.064591</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>72168.927986</td>\n",
              "      <td>406.345647</td>\n",
              "      <td>35.344886</td>\n",
              "      <td>40.828691</td>\n",
              "      <td>63.655682</td>\n",
              "      <td>454.480565</td>\n",
              "      <td>657.972302</td>\n",
              "      <td>453.019877</td>\n",
              "      <td>0.782911</td>\n",
              "      <td>22.273494</td>\n",
              "      <td>115.706115</td>\n",
              "      <td>0.844743</td>\n",
              "      <td>1.193585</td>\n",
              "      <td>453.596721</td>\n",
              "      <td>22.412081</td>\n",
              "      <td>1.214079</td>\n",
              "      <td>1.816763</td>\n",
              "      <td>22.064922</td>\n",
              "      <td>1.264982</td>\n",
              "      <td>1.816611</td>\n",
              "      <td>32.894693</td>\n",
              "      <td>1.812223</td>\n",
              "      <td>126.499506</td>\n",
              "      <td>0.977426</td>\n",
              "      <td>532.962789</td>\n",
              "      <td>489.338286</td>\n",
              "      <td>489.333883</td>\n",
              "      <td>479.875496</td>\n",
              "      <td>453.384624</td>\n",
              "      <td>453.389017</td>\n",
              "      <td>98.015662</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>100000.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>6.329000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.208000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>46.104000</td>\n",
              "      <td>0.047000</td>\n",
              "      <td>-1.414000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>20.000000</td>\n",
              "      <td>-2.499000</td>\n",
              "      <td>-3.142000</td>\n",
              "      <td>26.000000</td>\n",
              "      <td>-2.505000</td>\n",
              "      <td>-3.142000</td>\n",
              "      <td>0.109000</td>\n",
              "      <td>-3.142000</td>\n",
              "      <td>13.678000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>162499.750000</td>\n",
              "      <td>78.100750</td>\n",
              "      <td>19.241000</td>\n",
              "      <td>59.388750</td>\n",
              "      <td>14.068750</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>1.810000</td>\n",
              "      <td>2.841000</td>\n",
              "      <td>77.550000</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>-1.371000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>24.591750</td>\n",
              "      <td>-0.925000</td>\n",
              "      <td>-1.575000</td>\n",
              "      <td>32.375000</td>\n",
              "      <td>-1.014000</td>\n",
              "      <td>-1.522000</td>\n",
              "      <td>21.398000</td>\n",
              "      <td>-1.575000</td>\n",
              "      <td>123.017500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>224999.500000</td>\n",
              "      <td>105.012000</td>\n",
              "      <td>46.524000</td>\n",
              "      <td>73.752000</td>\n",
              "      <td>38.467500</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>2.491500</td>\n",
              "      <td>12.315500</td>\n",
              "      <td>120.664500</td>\n",
              "      <td>1.280000</td>\n",
              "      <td>-0.356000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>31.804000</td>\n",
              "      <td>-0.023000</td>\n",
              "      <td>-0.033000</td>\n",
              "      <td>40.516000</td>\n",
              "      <td>-0.045000</td>\n",
              "      <td>0.086000</td>\n",
              "      <td>34.802000</td>\n",
              "      <td>-0.024000</td>\n",
              "      <td>179.739000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>38.960000</td>\n",
              "      <td>-1.872000</td>\n",
              "      <td>-2.093000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>-999.000000</td>\n",
              "      <td>40.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>287499.250000</td>\n",
              "      <td>130.606250</td>\n",
              "      <td>73.598000</td>\n",
              "      <td>92.259000</td>\n",
              "      <td>79.169000</td>\n",
              "      <td>0.490000</td>\n",
              "      <td>83.446000</td>\n",
              "      <td>-4.593000</td>\n",
              "      <td>2.961000</td>\n",
              "      <td>27.591000</td>\n",
              "      <td>200.478250</td>\n",
              "      <td>1.777000</td>\n",
              "      <td>1.225000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>45.017000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>1.565000</td>\n",
              "      <td>53.390000</td>\n",
              "      <td>0.959000</td>\n",
              "      <td>1.618000</td>\n",
              "      <td>51.895000</td>\n",
              "      <td>1.561000</td>\n",
              "      <td>263.379250</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>75.349000</td>\n",
              "      <td>0.433000</td>\n",
              "      <td>0.503000</td>\n",
              "      <td>33.703000</td>\n",
              "      <td>-2.457000</td>\n",
              "      <td>-2.275000</td>\n",
              "      <td>109.933750</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>349999.000000</td>\n",
              "      <td>1192.026000</td>\n",
              "      <td>690.075000</td>\n",
              "      <td>1349.351000</td>\n",
              "      <td>2834.999000</td>\n",
              "      <td>8.503000</td>\n",
              "      <td>4974.979000</td>\n",
              "      <td>16.690000</td>\n",
              "      <td>5.684000</td>\n",
              "      <td>2834.999000</td>\n",
              "      <td>1852.462000</td>\n",
              "      <td>19.773000</td>\n",
              "      <td>1.414000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>764.408000</td>\n",
              "      <td>2.497000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>560.271000</td>\n",
              "      <td>2.503000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>2842.617000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>2003.976000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1120.573000</td>\n",
              "      <td>4.499000</td>\n",
              "      <td>3.141000</td>\n",
              "      <td>721.456000</td>\n",
              "      <td>4.500000</td>\n",
              "      <td>3.142000</td>\n",
              "      <td>1633.433000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             EventId   DER_mass_MMC  ...  PRI_jet_subleading_phi  PRI_jet_all_pt\n",
              "count  250000.000000  250000.000000  ...           250000.000000   250000.000000\n",
              "mean   224999.500000     -49.023079  ...             -709.118631       73.064591\n",
              "std     72168.927986     406.345647  ...              453.389017       98.015662\n",
              "min    100000.000000    -999.000000  ...             -999.000000        0.000000\n",
              "25%    162499.750000      78.100750  ...             -999.000000        0.000000\n",
              "50%    224999.500000     105.012000  ...             -999.000000       40.512500\n",
              "75%    287499.250000     130.606250  ...               -2.275000      109.933750\n",
              "max    349999.000000    1192.026000  ...                3.142000     1633.433000\n",
              "\n",
              "[8 rows x 31 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dyYho7fjRUt0"
      },
      "source": [
        "split = tts(higgsdata, label, weight, train_size=0.60)\n",
        "Xtrain, Xtest, Ltrain, Ltest, Wtrain, Wtest = split"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O8eUWMdVx983",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ad191f7-d79a-476a-db51-7754b9586e5f"
      },
      "source": [
        "label.values"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['s', 'b', 'b', ..., 's', 'b', 'b'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tv1otxd5yB-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1653900-b6f9-43fe-a1d5-f130108f3dd1"
      },
      "source": [
        "weight.values"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.00265331, 2.23358449, 2.34738894, ..., 0.01863612, 1.68161144,\n",
              "       1.87747381])"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sLK2qoS_oW_j"
      },
      "source": [
        "- Use a Random Forest and a Gradiend Boosted Tree Classifier model to predict the label of the particles. get the score of the model on the training and test set and comment on the result for each model.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KcbE8dfOubyE"
      },
      "source": [
        "max_depth_test = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, None]\n",
        "rng = np.random.RandomState(193)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "462TUGMFa0Fq",
        "outputId": "de5dbfa1-3726-4804-f7db-fdd4597d252f"
      },
      "source": [
        "for md in max_depth_test:\n",
        "    rf =  RandomForestClassifier(\n",
        "        n_estimators=10,\n",
        "        criterion=\"gini\",\n",
        "        max_depth=md,\n",
        "        random_state=rng\n",
        "    )\n",
        "    rf_fit = rf.fit(Xtrain, Ltrain)\n",
        "    test_score = rf.score(Xtest, Ltest)\n",
        "    train_score = rf.score(Xtrain, Ltrain)\n",
        "    print(f\"Max Depth: {md}\")\n",
        "    print(f\"    Train Score: {train_score:.3f}\")\n",
        "    print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 1\n",
            "    Train Score: 0.656\n",
            "    Test Score: 0.660\n",
            "Max Depth: 2\n",
            "    Train Score: 0.724\n",
            "    Test Score: 0.724\n",
            "Max Depth: 3\n",
            "    Train Score: 0.768\n",
            "    Test Score: 0.768\n",
            "Max Depth: 4\n",
            "    Train Score: 0.803\n",
            "    Test Score: 0.801\n",
            "Max Depth: 5\n",
            "    Train Score: 0.811\n",
            "    Test Score: 0.809\n",
            "Max Depth: 6\n",
            "    Train Score: 0.819\n",
            "    Test Score: 0.815\n",
            "Max Depth: 7\n",
            "    Train Score: 0.821\n",
            "    Test Score: 0.818\n",
            "Max Depth: 8\n",
            "    Train Score: 0.830\n",
            "    Test Score: 0.825\n",
            "Max Depth: 9\n",
            "    Train Score: 0.835\n",
            "    Test Score: 0.825\n",
            "Max Depth: 10\n",
            "    Train Score: 0.842\n",
            "    Test Score: 0.828\n",
            "Max Depth: None\n",
            "    Train Score: 0.988\n",
            "    Test Score: 0.821\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bB_PU5nzm5lC"
      },
      "source": [
        "# Random Forest Classifier Discussion\n",
        "\n",
        "We nootice that for the training and test sets the score of the classifier plateaus at a max depth of 4. We also note that at a max depth of 9 the test score is 1 percent lower than the train score. Setting max depth to none yields a fully overfitted dataset. We choose a max depth of 4 for this work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-B19BjqKnYq6",
        "outputId": "da22fd47-309e-47e1-e8e8-9624407b76df"
      },
      "source": [
        "rf =  RandomForestClassifier(\n",
        "    n_estimators=100,\n",
        "    criterion=\"gini\",\n",
        "    max_depth=4,\n",
        "    random_state=rng\n",
        ")\n",
        "rf_fit = rf.fit(Xtrain, Ltrain)\n",
        "test_score = rf.score(Xtest, Ltest)\n",
        "train_score = rf.score(Xtrain, Ltrain)\n",
        "print(f\"Max Depth: {4}\")\n",
        "print(f\"    Train Score: {train_score:.3f}\")\n",
        "print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: None\n",
            "    Train Score: 0.812\n",
            "    Test Score: 0.811\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MiYrAgfkhqia",
        "outputId": "c09c531e-8e44-415d-951e-9cec7e2100b9"
      },
      "source": [
        "for md in max_depth_test:\n",
        "    gbt =  GradientBoostingClassifier(\n",
        "        n_estimators=10,\n",
        "        # criterion=\"gini\",\n",
        "        max_depth=md,\n",
        "        random_state=rng\n",
        "    )\n",
        "    gbt_fit = gbt.fit(Xtrain, Ltrain)\n",
        "    test_score = gbt.score(Xtest, Ltest)\n",
        "    train_score = gbt.score(Xtrain, Ltrain)\n",
        "    print(f\"Max Depth: {md}\")\n",
        "    print(f\"    Train Score: {train_score:.3f}\")\n",
        "    print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 1\n",
            "    Train Score: 0.656\n",
            "    Test Score: 0.660\n",
            "Max Depth: 2\n",
            "    Train Score: 0.793\n",
            "    Test Score: 0.793\n",
            "Max Depth: 3\n",
            "    Train Score: 0.804\n",
            "    Test Score: 0.803\n",
            "Max Depth: 4\n",
            "    Train Score: 0.808\n",
            "    Test Score: 0.807\n",
            "Max Depth: 5\n",
            "    Train Score: 0.815\n",
            "    Test Score: 0.814\n",
            "Max Depth: 6\n",
            "    Train Score: 0.825\n",
            "    Test Score: 0.822\n",
            "Max Depth: 7\n",
            "    Train Score: 0.829\n",
            "    Test Score: 0.824\n",
            "Max Depth: 8\n",
            "    Train Score: 0.836\n",
            "    Test Score: 0.827\n",
            "Max Depth: 9\n",
            "    Train Score: 0.844\n",
            "    Test Score: 0.828\n",
            "Max Depth: 10\n",
            "    Train Score: 0.855\n",
            "    Test Score: 0.829\n",
            "Max Depth: None\n",
            "    Train Score: 1.000\n",
            "    Test Score: 0.768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ra82JayCndNv"
      },
      "source": [
        "# Gradient Boosting Classifier Discussion\n",
        "\n",
        "We nootice that for the training and test sets the score of the classifier plateaus at a max depth of 2 or 3. We also note that at a max depth of 8 the test score is almost 1 percent lower than the train score. Setting max depth to none yields a fully overfitted dataset. We choose a max depth of 3 for this work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VH3K3r-Sn6lj",
        "outputId": "48b5545c-7474-4eec-98a0-93da2feccfa2"
      },
      "source": [
        "gbt =  GradientBoostingClassifier(\n",
        "    n_estimators=100,\n",
        "    # criterion=\"gini\",\n",
        "    max_depth=3,\n",
        "    random_state=rng\n",
        ")\n",
        "gbt_fit = gbt.fit(Xtrain, Ltrain)\n",
        "test_score = gbt.score(Xtest, Ltest)\n",
        "train_score = gbt.score(Xtrain, Ltrain)\n",
        "print(f\"Max Depth: {3}\")\n",
        "print(f\"    Train Score: {train_score:.3f}\")\n",
        "print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: None\n",
            "    Train Score: 0.835\n",
            "    Test Score: 0.831\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6aiULt4TP8kn"
      },
      "source": [
        "- Produce a confusion matrix for each model and compare them\n",
        "\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ak3gnF6duviH"
      },
      "source": [
        "\n",
        "pl = plt\n",
        "# I creaded this function (mostly copied from sklearn examples). \n",
        "# You can use it to create the confusion matrix\n",
        "from mpl_toolkits.axes_grid1.axes_divider import make_axes_locatable\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(y_true, y_pred,\n",
        "                          normalize=False,\n",
        "                          title='',\n",
        "                          cmap=pl.cm.bone):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"         \n",
        "    if normalize:\n",
        "          title = title + ' Normalized confusion matrix'\n",
        "    else:\n",
        "          title = title + ' Confusion matrix, without normalization'\n",
        "\n",
        "    # Compute confusion matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    # plot it\n",
        "    fig, ax = plt.subplots(1, 1)\n",
        "    fig.subplots_adjust()\n",
        "    im = ax.imshow(cm, cmap=cmap)\n",
        "    ax_divider = make_axes_locatable(ax)\n",
        "    # add an axes to the right of the main axes.\n",
        "    pl.xticks([0, 1], labels=[\"N\", \"P\"])\n",
        "    pl.ylim(-0.5,1.5)\n",
        "    pl.yticks([0,1], labels=[\"N\", \"P\"])    \n",
        "    pl.title(title)\n",
        "    cax = ax_divider.append_axes(\"right\", size=\"10%\", pad=\"2%\")\n",
        "    cb = pl.colorbar(im, cax=cax)\n",
        "    "
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "isbiIC8qxEA6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "49aeabb6-d4ad-4ba3-d011-65333259246b"
      },
      "source": [
        "plot_confusion_matrix(rf.predict(Xtest.values), Ltest.values, title=\"RF\")"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T19ni5Vgq2FC"
      },
      "source": [
        "### Figure 1: Confusion matrix for the Random Forest classifier with a max depth of 4 and 100 estimators. We see that the model performs well at predicting true negatives, whereas prediciting true positives was more difficult for this model. Without domain knowledge, it is impossible to know whether this confusion matrix would be acceptable for the problem it is trying to solve."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRPWoZ0sr9VJ",
        "outputId": "525e3915-41ee-48a2-dee3-84d1fdde3287"
      },
      "source": [
        "Ltest.shape"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000,)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgQcTMFuxZV4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "outputId": "766934b7-17c2-4a24-aaae-fe1a16c05986"
      },
      "source": [
        "plot_confusion_matrix(gbt.predict(Xtest.values), Ltest.values, title=\"GBT\")"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uhdd_swQr12R"
      },
      "source": [
        "### Figure 2: Confusion matrix for the Gradient Boosting classifier with a max depth of 3 and 100 estimators. We see that the model performs well at predicting true negatives, whereas prediciting true positives was more difficult for this model. Without domain knowledge, it is impossible to know whether this confusion matrix would be acceptable for the problem it is trying to solve. This model performs similarly to the Random Forest Classifier shown in Figure 1."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TbZQ3kMSQFK6"
      },
      "source": [
        "\n",
        "- Use a Random Forest and a Gradiend Boosted Tree Regressor model to predict the weight of the particles. Compare the model performance on training and test setsm\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y3Kw9Ihjsl5x",
        "outputId": "c43d9261-6b26-4455-fe87-3ca66ec05609"
      },
      "source": [
        "for md in max_depth_test:\n",
        "    rfr =  RandomForestRegressor(\n",
        "        n_estimators=10,\n",
        "        criterion=\"squared_error\",\n",
        "        max_depth=md,\n",
        "        random_state=rng\n",
        "    )\n",
        "    rfr_fit = rfr.fit(Xtrain, Wtrain)\n",
        "    test_score = rfr.score(Xtest, Wtest)\n",
        "    train_score = rfr.score(Xtrain, Wtrain)\n",
        "    print(f\"Max Depth: {md}\")\n",
        "    print(f\"    Train Score: {train_score:.3f}\")\n",
        "    print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 1\n",
            "    Train Score: 0.253\n",
            "    Test Score: 0.253\n",
            "Max Depth: 2\n",
            "    Train Score: 0.417\n",
            "    Test Score: 0.417\n",
            "Max Depth: 3\n",
            "    Train Score: 0.480\n",
            "    Test Score: 0.478\n",
            "Max Depth: 4\n",
            "    Train Score: 0.523\n",
            "    Test Score: 0.520\n",
            "Max Depth: 5\n",
            "    Train Score: 0.554\n",
            "    Test Score: 0.550\n",
            "Max Depth: 6\n",
            "    Train Score: 0.583\n",
            "    Test Score: 0.575\n",
            "Max Depth: 7\n",
            "    Train Score: 0.602\n",
            "    Test Score: 0.588\n",
            "Max Depth: 8\n",
            "    Train Score: 0.621\n",
            "    Test Score: 0.600\n",
            "Max Depth: 9\n",
            "    Train Score: 0.639\n",
            "    Test Score: 0.605\n",
            "Max Depth: 10\n",
            "    Train Score: 0.661\n",
            "    Test Score: 0.611\n",
            "Max Depth: None\n",
            "    Train Score: 0.926\n",
            "    Test Score: 0.583\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94xMma4gttuD"
      },
      "source": [
        "We see that this random forest regressor starts to become overfitted at a max depth of about 7 when the test score lags behind the train score by more than 1 percent. We choose max depth of 6 for this work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wF-vF9BmuPqs",
        "outputId": "eb9b1c65-8971-43c0-8e72-fcccaeae9a06"
      },
      "source": [
        "rfr =  RandomForestRegressor(\n",
        "    n_estimators=100,\n",
        "    criterion=\"squared_error\",\n",
        "    max_depth=6,\n",
        "    random_state=rng\n",
        ")\n",
        "rfr_fit = rfr.fit(Xtrain, Wtrain)\n",
        "test_score = rfr.score(Xtest, Wtest)\n",
        "train_score = rfr.score(Xtrain, Wtrain)\n",
        "print(f\"Max Depth: {6}\")\n",
        "print(f\"    Train Score: {train_score:.3f}\")\n",
        "print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 6\n",
            "    Train Score: 0.584\n",
            "    Test Score: 0.576\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r0KiFqNguOSi",
        "outputId": "7769bc20-0420-42a2-a27e-6779cadd9bac"
      },
      "source": [
        "for md in max_depth_test:\n",
        "    gbtr =  GradientBoostingRegressor(\n",
        "        n_estimators=10,\n",
        "        criterion=\"squared_error\",\n",
        "        max_depth=md,\n",
        "        random_state=rng\n",
        "    )\n",
        "    gbtr_fit = gbtr.fit(Xtrain, Wtrain)\n",
        "    test_score = gbtr.score(Xtest, Wtest)\n",
        "    train_score = gbtr.score(Xtrain, Wtrain)\n",
        "    print(f\"Max Depth: {md}\")\n",
        "    print(f\"    Train Score: {train_score:.3f}\")\n",
        "    print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 1\n",
            "    Train Score: 0.289\n",
            "    Test Score: 0.289\n",
            "Max Depth: 2\n",
            "    Train Score: 0.406\n",
            "    Test Score: 0.404\n",
            "Max Depth: 3\n",
            "    Train Score: 0.452\n",
            "    Test Score: 0.449\n",
            "Max Depth: 4\n",
            "    Train Score: 0.484\n",
            "    Test Score: 0.480\n",
            "Max Depth: 5\n",
            "    Train Score: 0.505\n",
            "    Test Score: 0.498\n",
            "Max Depth: 6\n",
            "    Train Score: 0.522\n",
            "    Test Score: 0.512\n",
            "Max Depth: 7\n",
            "    Train Score: 0.538\n",
            "    Test Score: 0.524\n",
            "Max Depth: 8\n",
            "    Train Score: 0.553\n",
            "    Test Score: 0.531\n",
            "Max Depth: 9\n",
            "    Train Score: 0.570\n",
            "    Test Score: 0.536\n",
            "Max Depth: 10\n",
            "    Train Score: 0.591\n",
            "    Test Score: 0.539\n",
            "Max Depth: None\n",
            "    Train Score: 0.878\n",
            "    Test Score: 0.409\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dp_rLGJswYna"
      },
      "source": [
        "We see that this gradient boosting regressor starts to become overfitted at a max depth of about 6 when the test score lags behind the train score by almost 1 percent. We choose max depth of 5 for this work."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WH8zB9Q8upu7",
        "outputId": "061b1eb8-bd84-44ff-b4b5-5c4b03d1b3c6"
      },
      "source": [
        "gbtr =  GradientBoostingRegressor(\n",
        "    n_estimators=100,\n",
        "    criterion=\"squared_error\",\n",
        "    max_depth=5,\n",
        "    random_state=rng\n",
        ")\n",
        "gbtr_fit = gbtr.fit(Xtrain, Wtrain)\n",
        "test_score = gbtr.score(Xtest, Wtest)\n",
        "train_score = gbtr.score(Xtrain, Wtrain)\n",
        "print(f\"Max Depth: {5}\")\n",
        "print(f\"    Train Score: {train_score:.3f}\")\n",
        "print(f\"    Test Score: {test_score:.3f}\")"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Max Depth: 5\n",
            "    Train Score: 0.646\n",
            "    Test Score: 0.622\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CKvyqcFr3Z3d"
      },
      "source": [
        " Calculate the L2 and L1 loss functions for the fitted regression models (see slides for the definition) and discuss the results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUngfLrr0Mnl"
      },
      "source": [
        "def L(X, Y, model, p):\n",
        "    return np.sum(np.power(np.abs(Y - model.predict(X)), p), axis=0)"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UkanVFfO3HBe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73a42f09-0e5c-46f8-89a8-5024b0818932"
      },
      "source": [
        "print(f\"L1 RF: {L(Xtest, Wtest, rfr, 1)}\")\n",
        "print(f\"L2 RF: {L(Xtest, Wtest, rfr, 2)}\")\n",
        "print()\n",
        "print(f\"L1 GBT: {L(Xtest, Wtest, gbtr, 1)}\")\n",
        "print(f\"L2 GBT: {L(Xtest, Wtest, gbtr, 2)}\")"
      ],
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 RF: 88422.41038259173\n",
            "L2 RF: 149212.61167265577\n",
            "\n",
            "L1 GBT: 81314.48220373476\n",
            "L2 GBT: 132932.8809652285\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VKE-eTSA56dO"
      },
      "source": [
        "L1 and L2 loss functions calculated for the random forest and gradient boosting regressors. The criteria for quality of each split for both models was \"squared error\" which likely corresponds to the L2 loss function. In both cases, the gradient boosting model performs better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X9QZDqBM6Qiw"
      },
      "source": [
        "# For the Random Forest Classifier, select the 4 most important features (see how in the Titanic notebook)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ABhDz-2T6Tcr",
        "outputId": "46ea7b09-9571-4936-f2dd-a246b733e545"
      },
      "source": [
        "print(\"Random Forest feature importance\")\n",
        "for f, fi in zip(higgsdata.columns, rf.feature_importances_):\n",
        "  print(f, fi.round(2))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest feature importance\n",
            "EventId 0.0\n",
            "DER_mass_MMC 0.27\n",
            "DER_mass_transverse_met_lep 0.19\n",
            "DER_mass_vis 0.08\n",
            "DER_pt_h 0.01\n",
            "DER_deltaeta_jet_jet 0.03\n",
            "DER_mass_jet_jet 0.03\n",
            "DER_prodeta_jet_jet 0.01\n",
            "DER_deltar_tau_lep 0.02\n",
            "DER_pt_tot 0.0\n",
            "DER_sum_pt 0.02\n",
            "DER_pt_ratio_lep_tau 0.06\n",
            "DER_met_phi_centrality 0.09\n",
            "DER_lep_eta_centrality 0.03\n",
            "PRI_tau_pt 0.1\n",
            "PRI_tau_eta 0.0\n",
            "PRI_tau_phi 0.0\n",
            "PRI_lep_pt 0.0\n",
            "PRI_lep_eta 0.0\n",
            "PRI_lep_phi 0.0\n",
            "PRI_met 0.02\n",
            "PRI_met_phi 0.0\n",
            "PRI_met_sumet 0.0\n",
            "PRI_jet_num 0.0\n",
            "PRI_jet_leading_pt 0.01\n",
            "PRI_jet_leading_eta 0.0\n",
            "PRI_jet_leading_phi 0.0\n",
            "PRI_jet_subleading_pt 0.0\n",
            "PRI_jet_subleading_eta 0.0\n",
            "PRI_jet_subleading_phi 0.0\n",
            "PRI_jet_all_pt 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WkTu7XKn69hy"
      },
      "source": [
        "The four most important features are:\n",
        "*   DER_mass_MMC\n",
        "*   DER_mass_transverse_met_lep\n",
        "*   DER_met_phi_centrality\n",
        "*   DER_mass_vis\n",
        "\n",
        "These features represent:\n",
        "*   The estimated mass of the Higgs candidate.\n",
        "*   The transverse mass between the missing transverse energy and the leptop.\n",
        "*   The centrality of the azimuthal angle of the missing transverse energy vector w.r.t. the hadronic tau and the lepton.\n",
        "*   The invariant mass of the hadronic tau and the lepton.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c38At7ayYd_5"
      },
      "source": [
        "- For the Random Forest classifier, find the 4 most important features based on the simple unoptimized model you created earlier on. Use the documentation to find out what they are. We have not talked abotu the physics of this problem at all but the Kaggle challenge description should provide enogh information for you to comment on this result is somewhat superficially.\n",
        "\n",
        "    You can use ```rf.feature_importance_``` on the trained model to extract the relative importance of each feature (a number from 0 to 1) and then choose the features that have the 4 highest numbers (the numpy function ```argsort()``` is helpful here!)\n",
        "\n",
        "- Explore the parameter space with the sklearn module ```sklearn.model_selection.RandomizedSearchCV``` *fitting only those 4 features*\n",
        "\n",
        "    Follow this example to set up the parameter search. Set the estimators to 10 and 100, (the number of trees) and the max depth to 3, and 10, and None (let it be unconstrained). Set bootstrap to both True and False. Set the number of features to consider at every split to both \"autp\" and \"sqrt\". Use ```pprint``` like I did earlier in this notebook to print the parameters set\n",
        "\n",
        "**this takes some computational time! so do not start this at the last minute!!**\n",
        "\n",
        " \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xOO0ktrX7vdM"
      },
      "source": [
        "feats = [\"DER_mass_MMC\",\n",
        "         \"DER_mass_transverse_met_lep\",\n",
        "         \"DER_met_phi_centrality\",\n",
        "         \"DER_mass_vis\"]\n",
        "random_grid = {'max_depth': [3, 10, None],\n",
        "               'max_features': ['auto', 'sqrt'],\n",
        "               'n_estimators': [10, 100, 1000]}"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sm0OqNdJ8etb"
      },
      "source": [
        "RandomizedSearchCV?"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AJ70oqZPvL_"
      },
      "source": [
        "# Use the random grid to search for best hyperparameters\n",
        "# First create the base model to tune\n",
        "# Random search of parameters, using 3 fold cross validation, \n",
        "# search across 18 different combinations\n",
        "random_search = RandomizedSearchCV(estimator = rf, param_distributions=random_grid,\n",
        "                                   n_iter=1, cv=3)\n"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T3W60KM1Jb5r"
      },
      "source": [
        "Note that this may take a long time! It took 1 hour for me to run this. Dont start at the last minute!!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCzypqyrtsEg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cbb933bb-dcc7-4c4d-cbd9-be1d83bc1594"
      },
      "source": [
        "random_search.fit(Xtrain, y=Ltrain)\n",
        "                  "
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomizedSearchCV(cv=3,\n",
              "                   estimator=RandomForestClassifier(max_depth=4,\n",
              "                                                    random_state=RandomState(MT19937) at 0x7FA20AF9F160),\n",
              "                   n_iter=1,\n",
              "                   param_distributions={'max_depth': [3, 10, None],\n",
              "                                        'max_features': ['auto', 'sqrt'],\n",
              "                                        'n_estimators': [10, 100, 1000]})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GpfPW1HVDnDY",
        "outputId": "24cbabb3-bdbb-4892-a1f5-196d6c4c3bfe"
      },
      "source": [
        "random_search.best_estimator_"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(max_depth=10, n_estimators=1000,\n",
              "                       random_state=RandomState(MT19937) at 0x7FA20F6DAE20)"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weDZfbHJDsRm",
        "outputId": "d7c98f55-f740-4613-9e55-141a6913c346"
      },
      "source": [
        "random_search.best_params_"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'n_estimators': 1000, 'max_features': 'auto', 'max_depth': 10}"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-b40t1pDv0B"
      },
      "source": [
        "rf_random = RandomForestClassifier(**random_search.best_params_)"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y6hcHZ_TD5HE"
      },
      "source": [
        "rf_random_fit = rf_random.fit(Xtrain, Ltrain)"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_p-7lqtD-wv",
        "outputId": "d4faa086-10a1-409c-fe17-3235d46a9d03"
      },
      "source": [
        "rf_random_fit.score(Xtrain, Ltrain), rf_random_fit.score(Xtest, Ltest)"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.8439466666666666, 0.83072)"
            ]
          },
          "metadata": {},
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WaHvlFa27EV4"
      },
      "source": [
        "df = pd.DataFrame(random_search.cv_results_)\n"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pcXfIzb7eEw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "outputId": "93843273-cf0d-4b9a-a814-4a3cf275e186"
      },
      "source": [
        "df"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean_fit_time</th>\n",
              "      <th>std_fit_time</th>\n",
              "      <th>mean_score_time</th>\n",
              "      <th>std_score_time</th>\n",
              "      <th>param_n_estimators</th>\n",
              "      <th>param_max_features</th>\n",
              "      <th>param_max_depth</th>\n",
              "      <th>params</th>\n",
              "      <th>split0_test_score</th>\n",
              "      <th>split1_test_score</th>\n",
              "      <th>split2_test_score</th>\n",
              "      <th>mean_test_score</th>\n",
              "      <th>std_test_score</th>\n",
              "      <th>rank_test_score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>359.601106</td>\n",
              "      <td>1.413564</td>\n",
              "      <td>7.814248</td>\n",
              "      <td>0.250386</td>\n",
              "      <td>1000</td>\n",
              "      <td>auto</td>\n",
              "      <td>10</td>\n",
              "      <td>{'n_estimators': 1000, 'max_features': 'auto',...</td>\n",
              "      <td>0.83088</td>\n",
              "      <td>0.832</td>\n",
              "      <td>0.8315</td>\n",
              "      <td>0.83146</td>\n",
              "      <td>0.000458</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   mean_fit_time  std_fit_time  ...  std_test_score  rank_test_score\n",
              "0     359.601106      1.413564  ...        0.000458                1\n",
              "\n",
              "[1 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jiROnM7-E0n"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}